---
title: "HR attrition classifier"
author: "Kerim KiliÃ§"
subtitle: Supervised Machined Learning
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 2
    number_sections: true
    toc_float: true
---

# Libraries

The following three libraries are used in this R markdown file.

```{r setup, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
# devtools::install_github("jmsallan/BAdatasets")
library(BAdatasets)
```

# Dataset descriptive analytics and data split

```{r}
data("ibm_attrition")
ibm_attrition %>% glimpse()
```

Remove the following variables: *standardHours*, *Over18*, *EmployeeCount*, *EmployeeNumber* and transform the target variable *Attrition* into a factor.

```{r}
ibm_attrition <- ibm_attrition %>% 
  select(-StandardHours,-Over18,-EmployeeCount,-EmployeeNumber)

ibm_attrition <- ibm_attrition %>%
  mutate(Attrition = factor(Attrition, levels = c("Yes", "No")))
```

Setting the seed for reproducibility. Creating a variable with the logarithm of the target variable *price* and splitting the data into a training and test set.

```{r}
set.seed(2022)
ibm_split <- initial_split(ibm_attrition, prop = 0.8, strata = "Attrition")
```

# Recipe

```{r}
my_recipe <- training(ibm_split) %>%
  recipe(Attrition ~ .) %>%
  step_string2factor(all_nominal_predictors()) %>%
  step_corr(all_numeric_predictors()) %>%
  step_nzv(all_predictors()) %>%
  step_center(all_numeric_predictors()) %>%
  step_scale(all_numeric_predictors())

my_recipe
```

Glimpse into all the variables of the recipe.

```{r}
my_recipe %>% prep() %>% juice() %>% glimpse()
```

# Creating models

## Logistic regression

```{r}
glm <- logistic_reg(mode = "classification") %>%
  set_engine("glm")
```

## Random forest model

```{r}
rf <- rand_forest(mode = "classification", mtry = tune(), trees = tune()) %>%
  set_engine("ranger")
```

# Testing the models

## Metric sets and folds

```{r}
#class_metrics <- metric_set(accuracy, precision, recall)
```

Defining the number of folds for the cross validation to 4 and keeping repeats at 1 to minimize the time to train each model.

```{r}
folds <- vfold_cv(training(ibm_split), v = 4)
```

## Cross validation logistic regression model

```{r}
glm_wf <- workflow() %>%
  add_recipe(my_recipe) %>%
  add_model(glm) %>%
  fit(training(ibm_split))

glm_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  conf_mat(truth = Attrition, estimate = .pred_class)

glm_accuracy <- glm_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  accuracy(estimate = .pred_class, truth = Attrition)

glm_sensitivity <- glm_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  sensitivity(estimate = .pred_class, truth = Attrition)

glm_specificity <- glm_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  specificity(estimate = .pred_class, truth = Attrition)

glm_precision <- glm_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  precision(estimate = .pred_class, truth = Attrition)

glm_recall <- glm_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  precision(estimate = .pred_class, truth = Attrition)

glm_f_score <- glm_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  f_meas(estimate = .pred_class, truth = Attrition)

# F1 Score = 2*(Recall * Precision) / (Recall + Precision)
```

- Accuracy = `r round(glm_accuracy$.estimate[1],3)` 
- sensitivity = `r round(glm_sensitivity$.estimate[1],3)` 
- specificity = `r round(glm_specificity$.estimate[1],3)`
- precision = `r round(glm_precision$.estimate[1],3)`
- recall = `r round(glm_recall$.estimate[1],3)`
- F score = `r round(glm_f_score$.estimate[1],3)`

## Cross validation random forest model

Creating the workflow using the recipe and the random forest model with the ranger engine.

```{r}
wf_rf <- workflow() %>%
  add_recipe(my_recipe) %>%
  add_model(rf)
```

Setting the grid for hyper parameter tuning for the *mtry* and number of *trees*.

```{r}
rf_grid <- expand.grid(mtry = c(1, 3, 5, 7, 10), trees = c(5, 10, 15, 30, 50, 75, 100, 200, 300, 400, 500))
```

Cross validating and hyper parameter tuning the randomforest model.

```{r}
rf_tune <- tune_grid(object = rf, 
                     preprocessor = my_recipe, 
                     resamples = folds, 
                     grid = rf_grid, 
                     metrics = metric_set(accuracy, sensitivity, specificity, f_meas))

rf_result <- show_best(rf_tune, metric = "accuracy")

rf_result

####################################
### Fitting the entire train set ###
####################################

rf <- rand_forest(mode = "classification", mtry = 10, trees = 400) %>%
  set_engine("ranger")

final_wf <- workflow() %>%
  add_recipe(my_recipe) %>%
  add_model(rf) %>%
  fit(training(ibm_split))
```


```{r}
final_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  conf_mat(truth = Attrition, estimate = .pred_class)

rf_accuracy <- final_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  accuracy(estimate = .pred_class, truth = Attrition)

rf_sensitivity <- final_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  sensitivity(estimate = .pred_class, truth = Attrition)

rf_specificity <- final_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  specificity(estimate = .pred_class, truth = Attrition)

rf_precision <- final_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  precision(estimate = .pred_class, truth = Attrition)

rf_recall <- final_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  precision(estimate = .pred_class, truth = Attrition)

rf_f_score <- final_wf %>%
  predict(training(ibm_split)) %>%
  bind_cols(training(ibm_split)) %>%
  f_meas(estimate = .pred_class, truth = Attrition)

# F1 Score = 2*(Recall * Precision) / (Recall + Precision)
```

- Accuracy = `r round(rf_accuracy$.estimate[1],3)` 
- sensitivity = `r round(rf_sensitivity$.estimate[1],3)` 
- specificity = `r round(rf_specificity$.estimate[1],3)`
- precision = `r round(rf_precision$.estimate[1],3)`
- recall = `r round(rf_recall$.estimate[1],3)`
- F score = `r round(rf_f_score$.estimate[1],3)`

# Predicting the test set

## Random forest model

```{r}
predict_testing <- final_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  conf_mat(truth = Attrition, estimate = .pred_class)

rf_accuracy <- final_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  accuracy(estimate = .pred_class, truth = Attrition)

rf_sensitivity <- final_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  sensitivity(estimate = .pred_class, truth = Attrition)

rf_specificity <- final_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  specificity(estimate = .pred_class, truth = Attrition)

rf_precision <- final_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  precision(estimate = .pred_class, truth = Attrition)

rf_recall <- final_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  precision(estimate = .pred_class, truth = Attrition)

rf_f_score <- final_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  f_meas(estimate = .pred_class, truth = Attrition)

```

- Accuracy = `r round(rf_accuracy$.estimate[1],3)` 
- sensitivity = `r round(rf_sensitivity$.estimate[1],3)` 
- specificity = `r round(rf_specificity$.estimate[1],3)`
- precision = `r round(rf_precision$.estimate[1],3)`
- recall = `r round(rf_recall$.estimate[1],3)`
- F score = `r round(rf_f_score$.estimate[1],3)`

## Logistic regression model

```{r}
predict_testing <- glm_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  conf_mat(truth = Attrition, estimate = .pred_class)

glm_accuracy <- glm_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  accuracy(estimate = .pred_class, truth = Attrition)

glm_sensitivity <- glm_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  sensitivity(estimate = .pred_class, truth = Attrition)

glm_specificity <- glm_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  specificity(estimate = .pred_class, truth = Attrition)

glm_precision <- glm_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  precision(estimate = .pred_class, truth = Attrition)

glm_recall <- glm_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  precision(estimate = .pred_class, truth = Attrition)

glm_f_score <- glm_wf %>%
  predict(testing(ibm_split)) %>%
  bind_cols(testing(ibm_split)) %>%
  f_meas(estimate = .pred_class, truth = Attrition)
```

- Accuracy = `r round(glm_accuracy$.estimate[1],3)` 
- sensitivity = `r round(glm_sensitivity$.estimate[1],3)` 
- specificity = `r round(glm_specificity$.estimate[1],3)`
- precision = `r round(glm_precision$.estimate[1],3)`
- recall = `r round(glm_recall$.estimate[1],3)`
- F score = `r round(glm_f_score$.estimate[1],3)`
